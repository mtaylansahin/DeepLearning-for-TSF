{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bee621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import mlp, lstm, cnn\n",
    "\n",
    "\n",
    "X, y = sliding_window_preprocessing(df2, 3, 2)\n",
    "model = lstm(X.shape, horizon=2, return_sequences=True, loss=\"mse\", lstm_layers=[100, 100])\n",
    "model.fit(X, y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_scaling(model.predict(np.array(X_scaler.transform([[70, 75], [80, 85], [90, 95]]).reshape(1, 3, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14809e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_preprocessing(sequences, history_window, horizon=1, target_col=None):\n",
    "    if target_col:\n",
    "        target = sequences.pop(target_col)\n",
    "        sequences[target_col] = target\n",
    "    sequences = np.array(sequences)\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + history_window\n",
    "        horizon_end_ix = end_ix + horizon - 1\n",
    "        # check if we are beyond the sequence\n",
    "        if horizon_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:horizon_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e961995",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[ 10, 15, 25], [ 20, 25, 45], [ 30, 35, 65],\n",
    "                [ 40, 45, 85], [ 50, 55, 105], [ 60, 65, 125],\n",
    "                [ 70, 75, 145], [ 80, 85, 165], [ 90, 95, 185]])\n",
    "df = pd.DataFrame(arr, columns=[\"num1\", \"num2\", \"sum\"])\n",
    "\n",
    "X, y = sliding_window_preprocessing(df, 2, 2)\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b43c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_with_breakdown(sequence, history_window, horizon, breakdown_indices):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "Y_scaler = MinMaxScaler()\n",
    "\n",
    "def feature_scaling(sequences, target):\n",
    "    X_data = X_scaler.fit_transform(sequences.drop([target], axis=1))\n",
    "    Y_data = Y_scaler.fit_transform(sequences[target].values.reshape(-1, 1))\n",
    "    \n",
    "    return X_data, Y_data\n",
    "\n",
    "def inverse_scaling(y):\n",
    "    return Y_scaler.inverse_transform(y)\n",
    "\n",
    "df2 = df.copy()\n",
    "df2[[\"num1\", \"num2\"]], df2[\"sum\"] = feature_scaling(df, \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b885313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
