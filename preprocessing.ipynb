{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44de8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# FIXME: breakdown handling: sliding_window_with breakdown returns unencoded strings\n",
    "# TODO: label handling: is this best practice, can I transform back, do I need to transform it back\n",
    "# TODO: train test split\n",
    "# TODO: run prepare_test_data at constructor\n",
    "# TODO: testing\n",
    "class DataPreparation:\n",
    "    \n",
    "    def __init__(self, dataset, history_window, horizon=1, target_column=None, breakdown_columns=[]):\n",
    "        self.X_scaler = MinMaxScaler()\n",
    "        self.Y_scaler = MinMaxScaler()\n",
    "        self.validate = pd.DataFrame() \n",
    "        self.dataset = dataset\n",
    "        self.history_window = history_window\n",
    "        self.horizon = horizon\n",
    "        self.target = target_column\n",
    "        self.breakdown = breakdown_columns\n",
    "        \n",
    "        self.prepare_data()\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        if len(self.breakdown) > 0:\n",
    "            label_encoded_data = self.handle_labels(self.dataset, self.breakdown)\n",
    "            scaled_data = self.feature_scaling(label_encoded_data, self.target, self.breakdown)\n",
    "            self.X, self.y = self.sliding_window_with_breakdown(\n",
    "                scaled_data, self.history_window, self.horizon, self.target, self.breakdown)\n",
    "        else:\n",
    "            label_encoded_data = self.handle_labels(dataset)\n",
    "            scaled_data = self.feature_scaling(label_encoded_data, target_column)\n",
    "            self.X, self.y = self.sliding_window_preprocessing(scaled_data, history_window, horizon, target_column)\n",
    "    \n",
    "    def prepare_test_data(self, data):\n",
    "        if len(self.breakdown) > 0:\n",
    "            label_encoded_data = self.handle_labels(data, self.breakdown)\n",
    "            scaled_data = self.feature_scaling(label_encoded_data, self.target, self.breakdown, test=True)\n",
    "            X_test, y_test = self.sliding_window_with_breakdown(\n",
    "                scaled_data, self.history_window, self.horizon, self.target, self.breakdown, test=True)\n",
    "        else:\n",
    "            label_encoded_data = self.handle_labels(data)\n",
    "            scaled_data = self.feature_scaling(label_encoded_data, target_column)\n",
    "            X_test, y_test = self.sliding_window_preprocessing(scaled_data, history_window, horizon, target_column, test=True)\n",
    "        return X_test, self.inverse_scaling(y_test)\n",
    "    \n",
    "    def sliding_window_preprocessing(self, sequences, history_window, horizon=1, target_col=None, test=False):\n",
    "        if target_col:\n",
    "            target = sequences.pop(target_col)\n",
    "            sequences[target_col] = target\n",
    "        \n",
    "        if not test:\n",
    "            self.validate.append(sequences.tail(horizon).copy())\n",
    "            sequences.drop(sequences.tail(horizon).index, inplace=True)\n",
    "        \n",
    "        sequences = np.array(sequences)\n",
    "\n",
    "        X, y = list(), list()\n",
    "        for i in range(len(sequences)):\n",
    "            # find the end of this pattern\n",
    "            end_ix = i + history_window\n",
    "            horizon_end_ix = end_ix + horizon - 1\n",
    "            # check if we are beyond the sequence\n",
    "            if horizon_end_ix > len(sequences):\n",
    "                break\n",
    "            # gather input and output parts of the pattern\n",
    "            seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:horizon_end_ix, -1]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def sliding_window_with_breakdown(self, sequences, history_window, horizon=1, target_col=None, breakdown_columns=[], test=False):\n",
    "        assert len(breakdown_columns) > 0 \n",
    "        \n",
    "        X, y = np.array([]), np.array([])\n",
    "        cols = sequences[breakdown_columns].drop_duplicates()\n",
    "        for row in cols.values:\n",
    "            q = []\n",
    "            for col_name, val in zip(breakdown_columns, row):\n",
    "                if type(val) == int or type(val) == float:\n",
    "                    q.append(f\"{col_name}=={val}\")\n",
    "                else:\n",
    "                    q.append(f\"{col_name}=='{val}'\")\n",
    "\n",
    "            q = \" and \".join(q)\n",
    "            temp_df = sequences.query(q).copy()\n",
    "            if not test:\n",
    "                if len(temp_df) < history_window+horizon:\n",
    "                    continue\n",
    "\n",
    "                self.validate = self.validate.append(temp_df.tail(horizon).copy())\n",
    "                temp_df.drop(temp_df.tail(horizon).index, inplace=True)\n",
    "\n",
    "            if len(temp_df) < history_window+horizon:\n",
    "                # print(len(temp_df), q)\n",
    "                continue\n",
    "            X_temp, y_temp = self.sliding_window_preprocessing(temp_df, history_window, horizon, target_col, test=True)\n",
    "            if X.size == 0:\n",
    "                X = X_temp.copy()\n",
    "            else:\n",
    "                X = np.concatenate((X, X_temp))\n",
    "            if y.size == 0:\n",
    "                y = y_temp.copy()\n",
    "            else:\n",
    "                y = np.concatenate((y, y_temp))\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def handle_labels(self, sequences, ignore_cols=[]):\n",
    "        label_columns = []\n",
    "        for dtype, col in zip(sequences.dtypes, sequences.columns):\n",
    "            if dtype == \"object\" and col not in ignore_cols:\n",
    "                label_columns.append(col)\n",
    "        if len(label_columns) < 1:\n",
    "            return sequences\n",
    "        sequences = pd.concat([sequences, pd.get_dummies(sequences[label_columns], prefix='OneHot', drop_first=True)], axis=1)\n",
    "        return sequences.drop(label_columns, axis=1)\n",
    "\n",
    "    def feature_scaling(self, sequences, target_column, ignore_cols=[], test=False):\n",
    "        labels = sequences[ignore_cols]\n",
    "        feature_columns = sequences.drop([target_column]+ignore_cols, axis=1).columns.values\n",
    "        \n",
    "        if not test:\n",
    "            self.X_scaler.fit(sequences[feature_columns])\n",
    "            self.Y_scaler.fit(sequences[target_column].values.reshape(-1, 1))\n",
    "        \n",
    "        X_data = self.X_scaler.transform(sequences[feature_columns])\n",
    "        Y_data = self.Y_scaler.transform(sequences[target_column].values.reshape(-1, 1))\n",
    "            \n",
    "        sequences[feature_columns], sequences[target_column] = X_data, Y_data\n",
    "        sequences[ignore_cols] = labels\n",
    "        return sequences\n",
    "\n",
    "    def inverse_scaling(self, y):\n",
    "        return self.Y_scaler.inverse_transform(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
